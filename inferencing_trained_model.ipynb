{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc60777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "469834b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bceaecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparmeters\n",
    "batch_size = 64\n",
    "vocab_size = 65\n",
    "block_size = 256\n",
    "max_iters = 3000\n",
    "eval_intervals = 300\n",
    "learning_rate = 3e-4\n",
    "n_embd = 384\n",
    "n_head = 4\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c3a6a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path='input.txt'):\n",
    "    with open(path, 'r',encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    chars = sorted(list(set(text)))\n",
    "    vocab_size = len(chars)\n",
    "\n",
    "    stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "    itos = {i: ch for i, ch in enumerate(chars)}\n",
    "    encode = lambda s: [stoi[c] for c in s]\n",
    "    decode = lambda l: ''.join([itos[n] for n in l])\n",
    "\n",
    "    data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "    # Split once and return both splits\n",
    "    split_idx = int(0.9 * len(data))\n",
    "    train_data = data[:split_idx]\n",
    "    val_data = data[split_idx:]\n",
    "\n",
    "    return {\n",
    "        'train_data': train_data,\n",
    "        'val_data': val_data,\n",
    "        'vocab_size': vocab_size,\n",
    "        'stoi': stoi,\n",
    "        'itos': itos,\n",
    "        'encode': encode,\n",
    "        'decode': decode\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08af86e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_data': tensor([18, 47, 56,  ..., 43, 56, 43]),\n",
       " 'val_data': tensor([12,  0,  0,  ..., 45,  8,  0]),\n",
       " 'vocab_size': 65,\n",
       " 'stoi': {'\\n': 0,\n",
       "  ' ': 1,\n",
       "  '!': 2,\n",
       "  '$': 3,\n",
       "  '&': 4,\n",
       "  \"'\": 5,\n",
       "  ',': 6,\n",
       "  '-': 7,\n",
       "  '.': 8,\n",
       "  '3': 9,\n",
       "  ':': 10,\n",
       "  ';': 11,\n",
       "  '?': 12,\n",
       "  'A': 13,\n",
       "  'B': 14,\n",
       "  'C': 15,\n",
       "  'D': 16,\n",
       "  'E': 17,\n",
       "  'F': 18,\n",
       "  'G': 19,\n",
       "  'H': 20,\n",
       "  'I': 21,\n",
       "  'J': 22,\n",
       "  'K': 23,\n",
       "  'L': 24,\n",
       "  'M': 25,\n",
       "  'N': 26,\n",
       "  'O': 27,\n",
       "  'P': 28,\n",
       "  'Q': 29,\n",
       "  'R': 30,\n",
       "  'S': 31,\n",
       "  'T': 32,\n",
       "  'U': 33,\n",
       "  'V': 34,\n",
       "  'W': 35,\n",
       "  'X': 36,\n",
       "  'Y': 37,\n",
       "  'Z': 38,\n",
       "  'a': 39,\n",
       "  'b': 40,\n",
       "  'c': 41,\n",
       "  'd': 42,\n",
       "  'e': 43,\n",
       "  'f': 44,\n",
       "  'g': 45,\n",
       "  'h': 46,\n",
       "  'i': 47,\n",
       "  'j': 48,\n",
       "  'k': 49,\n",
       "  'l': 50,\n",
       "  'm': 51,\n",
       "  'n': 52,\n",
       "  'o': 53,\n",
       "  'p': 54,\n",
       "  'q': 55,\n",
       "  'r': 56,\n",
       "  's': 57,\n",
       "  't': 58,\n",
       "  'u': 59,\n",
       "  'v': 60,\n",
       "  'w': 61,\n",
       "  'x': 62,\n",
       "  'y': 63,\n",
       "  'z': 64},\n",
       " 'itos': {0: '\\n',\n",
       "  1: ' ',\n",
       "  2: '!',\n",
       "  3: '$',\n",
       "  4: '&',\n",
       "  5: \"'\",\n",
       "  6: ',',\n",
       "  7: '-',\n",
       "  8: '.',\n",
       "  9: '3',\n",
       "  10: ':',\n",
       "  11: ';',\n",
       "  12: '?',\n",
       "  13: 'A',\n",
       "  14: 'B',\n",
       "  15: 'C',\n",
       "  16: 'D',\n",
       "  17: 'E',\n",
       "  18: 'F',\n",
       "  19: 'G',\n",
       "  20: 'H',\n",
       "  21: 'I',\n",
       "  22: 'J',\n",
       "  23: 'K',\n",
       "  24: 'L',\n",
       "  25: 'M',\n",
       "  26: 'N',\n",
       "  27: 'O',\n",
       "  28: 'P',\n",
       "  29: 'Q',\n",
       "  30: 'R',\n",
       "  31: 'S',\n",
       "  32: 'T',\n",
       "  33: 'U',\n",
       "  34: 'V',\n",
       "  35: 'W',\n",
       "  36: 'X',\n",
       "  37: 'Y',\n",
       "  38: 'Z',\n",
       "  39: 'a',\n",
       "  40: 'b',\n",
       "  41: 'c',\n",
       "  42: 'd',\n",
       "  43: 'e',\n",
       "  44: 'f',\n",
       "  45: 'g',\n",
       "  46: 'h',\n",
       "  47: 'i',\n",
       "  48: 'j',\n",
       "  49: 'k',\n",
       "  50: 'l',\n",
       "  51: 'm',\n",
       "  52: 'n',\n",
       "  53: 'o',\n",
       "  54: 'p',\n",
       "  55: 'q',\n",
       "  56: 'r',\n",
       "  57: 's',\n",
       "  58: 't',\n",
       "  59: 'u',\n",
       "  60: 'v',\n",
       "  61: 'w',\n",
       "  62: 'x',\n",
       "  63: 'y',\n",
       "  64: 'z'},\n",
       " 'encode': <function __main__.load_dataset.<locals>.<lambda>(s)>,\n",
       " 'decode': <function __main__.load_dataset.<locals>.<lambda>(l)>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a04446fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigram import BigramLanguageModel,load_dataset\n",
    "dataset = load_dataset('input.txt')\n",
    "decode = dataset['decode']\n",
    "encode = dataset['encode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ff8022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramLanguageModel(vocab_size,n_embd,n_head,block_size,dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b6124c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BigramLanguageModel(\n",
       "  (token_embedding_table): Embedding(65, 384)\n",
       "  (position_embedding_table): Embedding(256, 384)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=384, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.load(\"bigram_model_weights.pth\", map_location=\"cpu\") \n",
    "model.load_state_dict(state)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f599ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device).eval()\n",
    "idx = torch.zeros((1, 1), dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9c9cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(self, idx, max_tokens):\n",
    "    # Get device from model parameters\n",
    "    device = next(self.parameters()).device\n",
    "    \n",
    "    # Ensure input tensor is on the correct device\n",
    "    idx = idx.to(device)\n",
    "    \n",
    "    for _ in range(max_tokens):\n",
    "        # Clip context window\n",
    "        idx_cond = idx[:, -block_size:]\n",
    "        \n",
    "        # Forward pass\n",
    "        logits, loss = self(idx_cond)\n",
    "        \n",
    "        # Get last logits and compute probabilities\n",
    "        logits = logits[:, -1, :]\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        \n",
    "        # Sample next token (will inherit device from probs)\n",
    "        idnext = torch.multinomial(probs, num_samples=1)\n",
    "        \n",
    "        # Concatenate with running sequence\n",
    "        idx = torch.cat((idx, idnext), dim=1)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d87713c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generate text\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 3\u001b[0m     out \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(idx, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n",
      "File \u001b[0;32m~/makemore_karpathy/nn_hero_zero4_transformers/bigram.py:187\u001b[0m, in \u001b[0;36mBigramLanguageModel.generate\u001b[0;34m(self, idx, max_tokens)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_tokens):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# when our generation grows longer than block_size, we would still want to feed in 8 characters at a time, as this ensures we never run out of scope in our embedding table which is (block_size ,n_embd)\u001b[39;00m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# so we clip the idx, to only contain the last 8 tokens or whatever blocks_size we chose\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     idx_cond \u001b[38;5;241m=\u001b[39m idx[:, \u001b[38;5;241m-\u001b[39mblock_size:] \n\u001b[0;32m--> 187\u001b[0m     logits,loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(idx_cond)\n\u001b[1;32m    188\u001b[0m     logits \u001b[38;5;241m=\u001b[39m logits[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:] \u001b[38;5;66;03m# only get the last logit\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(logits,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/makemore_karpathy/nn_hero_zero4_transformers/bigram.py:166\u001b[0m, in \u001b[0;36mBigramLanguageModel.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# we grab the corresponding embeddings\u001b[39;00m\n\u001b[1;32m    165\u001b[0m token_embd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_embedding_table(idx) \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m pos_embd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_table(torch\u001b[38;5;241m.\u001b[39marange(T,device\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[1;32m    167\u001b[0m x \u001b[38;5;241m=\u001b[39m token_embd \u001b[38;5;241m+\u001b[39m pos_embd \u001b[38;5;66;03m#addition as we're just adding in the context of position\u001b[39;00m\n\u001b[1;32m    168\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks(x)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39membedding(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx,\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_norm,\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type,\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_grad_by_freq,\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse,\n\u001b[1;32m    198\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39membedding(weight, \u001b[38;5;28minput\u001b[39m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "with torch.no_grad():\n",
    "    out = model.generate(idx, max_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83adfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: mps:0\n",
      "Input device: mps:0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mnext\u001b[39m(model\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "print(f\"Input device: {idx.device}\")\n",
    "print(f\"Output device: {out.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca104e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Leave me insible Tyrrel, if you persuade me certain a\n",
      "promise-keys! I dreamter, not but 't.\n",
      "\n",
      "PERDITA:\n",
      "Prepare you, sir, an you say?\n",
      "\n",
      "POLIXENES:\n",
      "Even in your honour impose:\n",
      "This Hery brother's name, banishment's gladly,\n",
      "Silence we are but by your judgment-seath!\n",
      "Fearest with the foe, Northphy, nor me.\n",
      "I cannot petence nor ago: there thoughts now,\n",
      "Some shall gentle to those by-walls.\n",
      "Away with his tale stone nobing wife;\n",
      "A pright tenous vantage brawled floads with miss,\n",
      "So doubtle prince and him, and married himself\n",
      "The judge, to a fooler, nay on the tractor,\n",
      "In that he doth vengeance of the closet,\n",
      "Were equest, where were best our to kitle way,\n",
      "Shook upon the hazards: we that thither came\n",
      "To conquire the than you sought with cholers,\n",
      "Lead, the heart of my baggage, consider\n",
      "Even to make him at a figure.\n",
      "\n",
      "JOHN OF GAUNT:\n",
      "What stir the worlds are is here small an approbation.\n",
      "\n",
      "KING RICHARD II:\n",
      "How have't! lay the hours me a sworn hour names!\n",
      "How canst he love to help.\n",
      "\n",
      "JOHN OF GAUNT:\n",
      "Whate'\n"
     ]
    }
   ],
   "source": [
    "print(''.join(decode(out[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e315860b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(out[0],bins=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35659250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1 mps available: True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__, \"mps available:\", torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7121aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_embedding_table.weight mps:0\n",
      "position_embedding_table.weight mps:0\n",
      "blocks.0.sa.heads.0.key.weight mps:0\n",
      "blocks.0.sa.heads.0.query.weight mps:0\n",
      "blocks.0.sa.heads.0.value.weight mps:0\n",
      "blocks.0.sa.heads.1.key.weight mps:0\n",
      "blocks.0.sa.heads.1.query.weight mps:0\n",
      "blocks.0.sa.heads.1.value.weight mps:0\n",
      "blocks.0.sa.heads.2.key.weight mps:0\n",
      "blocks.0.sa.heads.2.query.weight mps:0\n",
      "blocks.0.sa.heads.2.value.weight mps:0\n",
      "blocks.0.sa.heads.3.key.weight mps:0\n",
      "blocks.0.sa.heads.3.query.weight mps:0\n",
      "blocks.0.sa.heads.3.value.weight mps:0\n",
      "blocks.0.sa.proj.weight mps:0\n",
      "blocks.0.sa.proj.bias mps:0\n",
      "blocks.0.ffwd.net.0.weight mps:0\n",
      "blocks.0.ffwd.net.0.bias mps:0\n",
      "blocks.0.ffwd.net.2.weight mps:0\n",
      "blocks.0.ffwd.net.2.bias mps:0\n",
      "blocks.0.ln1.weight mps:0\n",
      "blocks.0.ln1.bias mps:0\n",
      "blocks.0.ln2.weight mps:0\n",
      "blocks.0.ln2.bias mps:0\n",
      "blocks.1.sa.heads.0.key.weight mps:0\n",
      "blocks.1.sa.heads.0.query.weight mps:0\n",
      "blocks.1.sa.heads.0.value.weight mps:0\n",
      "blocks.1.sa.heads.1.key.weight mps:0\n",
      "blocks.1.sa.heads.1.query.weight mps:0\n",
      "blocks.1.sa.heads.1.value.weight mps:0\n",
      "blocks.1.sa.heads.2.key.weight mps:0\n",
      "blocks.1.sa.heads.2.query.weight mps:0\n",
      "blocks.1.sa.heads.2.value.weight mps:0\n",
      "blocks.1.sa.heads.3.key.weight mps:0\n",
      "blocks.1.sa.heads.3.query.weight mps:0\n",
      "blocks.1.sa.heads.3.value.weight mps:0\n",
      "blocks.1.sa.proj.weight mps:0\n",
      "blocks.1.sa.proj.bias mps:0\n",
      "blocks.1.ffwd.net.0.weight mps:0\n",
      "blocks.1.ffwd.net.0.bias mps:0\n",
      "blocks.1.ffwd.net.2.weight mps:0\n",
      "blocks.1.ffwd.net.2.bias mps:0\n",
      "blocks.1.ln1.weight mps:0\n",
      "blocks.1.ln1.bias mps:0\n",
      "blocks.1.ln2.weight mps:0\n",
      "blocks.1.ln2.bias mps:0\n",
      "blocks.2.sa.heads.0.key.weight mps:0\n",
      "blocks.2.sa.heads.0.query.weight mps:0\n",
      "blocks.2.sa.heads.0.value.weight mps:0\n",
      "blocks.2.sa.heads.1.key.weight mps:0\n",
      "blocks.2.sa.heads.1.query.weight mps:0\n",
      "blocks.2.sa.heads.1.value.weight mps:0\n",
      "blocks.2.sa.heads.2.key.weight mps:0\n",
      "blocks.2.sa.heads.2.query.weight mps:0\n",
      "blocks.2.sa.heads.2.value.weight mps:0\n",
      "blocks.2.sa.heads.3.key.weight mps:0\n",
      "blocks.2.sa.heads.3.query.weight mps:0\n",
      "blocks.2.sa.heads.3.value.weight mps:0\n",
      "blocks.2.sa.proj.weight mps:0\n",
      "blocks.2.sa.proj.bias mps:0\n",
      "blocks.2.ffwd.net.0.weight mps:0\n",
      "blocks.2.ffwd.net.0.bias mps:0\n",
      "blocks.2.ffwd.net.2.weight mps:0\n",
      "blocks.2.ffwd.net.2.bias mps:0\n",
      "blocks.2.ln1.weight mps:0\n",
      "blocks.2.ln1.bias mps:0\n",
      "blocks.2.ln2.weight mps:0\n",
      "blocks.2.ln2.bias mps:0\n",
      "blocks.3.weight mps:0\n",
      "blocks.3.bias mps:0\n",
      "lm_head.weight mps:0\n",
      "lm_head.bias mps:0\n",
      "input device: mps:0\n"
     ]
    }
   ],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    print(name, p.device)\n",
    "print(\"input device:\", idx.device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
